package bm.hadoop.join;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapred.FileSplit;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.filecache.DistributedCache;

public class GenericReplicatedJoin extends
		Mapper<Object, Object, Object, Object> {
	private Map<Object, List<Pair>> cachedRecords = new HashMap<Object, List<Pair>>();
	private boolean distributedCacheIsSmaller;
	private Path[] distributedCacheFiles;

	public IDistributedCacheFileReader getDistributedCacheReader() {
		return new TextDistributedCacheFileReader();
	}

	@Override
	protected void map(Object key, Object value,
			Mapper<Object, Object, Object, Object>.Context context)
			throws IOException, InterruptedException {
		// TODO Auto-generated method stub
		super.map(key, value, context);
	}

	@SuppressWarnings("deprecation")
	@Override
	protected void setup(Mapper<Object, Object, Object, Object>.Context context)
			throws IOException, InterruptedException {
		super.setup(context);
		distributedCacheFiles = context.getLocalCacheFiles();

		int distCacheSizes = 0;
	    for (Path distFile : distributedCacheFiles) {
	      File distributedCacheFile = new File(distFile.toString());
	      distCacheSizes += distributedCacheFile.length();
	    }

	    if(context.getInputSplit() instanceof FileSplit) {
	      FileSplit split = (FileSplit) context.getInputSplit();

	      long inputSplitSize = split.getLength();

	      distributedCacheIsSmaller = (distCacheSizes < inputSplitSize);
	    } else {
	      // if the input split isn't a FileSplit, then assume the
	      // distributed cache is smaller than the input split
	      //
	      distributedCacheIsSmaller = true;
	    }


	    System.out.println(
	        "distributedCacheIsSmaller = " + distributedCacheIsSmaller);

	    if (distributedCacheIsSmaller) {
	      for (Path distFile : distributedCacheFiles) {
	        File distributedCacheFile = new File(distFile.toString());
	        IDistributedCacheFileReader<String, String> reader =
	            getDistributedCacheReader();
	        reader.init(distributedCacheFile);
	        for (Pair p : (Iterable<Pair>) reader) {
	          addToCache(p);
	        }
	        reader.close();
	      }
	    }
	  }

	  private void addToCache(Pair pair) {
	    List<Pair> values = cachedRecords.get(pair.getKey());
	    if (values == null) {
	      values = new ArrayList<Pair>();
	      cachedRecords.put(pair.getKey(), values);
	    }
	    values.add(pair);
	  }


}
